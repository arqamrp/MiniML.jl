{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onehot (generic function with 3 methods)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/tensor.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/utility.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/ops/unary.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/ops/scalar.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/ops/tensor_ops.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/ops/binary.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/nn/mlp.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/nn/activations.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/autograd.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/nn/optim.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/nn/losses.jl\")\n",
    "include(\"/Users/arqam/Downloads/miniML.jl-main/src/std_tensors.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m      Compat\u001b[22m\u001b[39m entries added for \n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Downloads/miniML.jl-main/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Downloads/miniML.jl-main/Manifest.toml`\n",
      "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "         \u001b[91m  ✗ \u001b[39mminiML\n",
      "  0 dependencies successfully precompiled in 6 seconds. 201 already precompiled.\n",
      "  \u001b[91m1\u001b[39m dependency errored.\n",
      "  For a report of the errors see `julia> err`. To retry use `pkg> precompile`\n"
     ]
    }
   ],
   "source": [
    "] add MLDatasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mMNIST.traindata() is deprecated, use `MNIST(split=:train)[:]` instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLDatasets ~/.julia/packages/MLDatasets/0MkOE/src/datasets/vision/mnist.jl:187\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mMNIST.testdata() is deprecated, use `MNIST(split=:test)[:]` instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLDatasets ~/.julia/packages/MLDatasets/0MkOE/src/datasets/vision/mnist.jl:195\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(features = FixedPointNumbers.N0f8[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8;;; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8;;; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8;;; … ;;; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8;;; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8;;; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8], targets = [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets\n",
    "\n",
    "\n",
    "train_x, train_y = MNIST.traindata()\n",
    "test_x, test_y = MNIST.testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×60000 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = Float64.(test_x)\n",
    "X_test = reshape(X_test, 784, 10000)\n",
    "y_test = Int64.(test_y)\n",
    "\n",
    "y_train = Int64.(train_y)\n",
    "X_train= reshape(train_x, (784, 60000))\n",
    "X_train = Float64.(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_batches (generic function with 2 methods)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_batches(X::AbstractArray, y::AbstractArray, batch_size::Integer)\n",
    "    n_samples = size(X)[2]\n",
    "    shuffled_indices = randperm(n_samples)\n",
    "    X_shuffled = X[:, shuffled_indices]\n",
    "    y_shuffled = y[shuffled_indices]\n",
    "\n",
    "    n_batches = div(n_samples, batch_size)\n",
    "    X_batches = Vector{Tensor}(undef, n_batches)\n",
    "    y_batches = Vector{Tensor}(undef, n_batches)\n",
    "    \n",
    "    for i in 1:n_batches\n",
    "        start_idx = (i - 1) * batch_size + 1\n",
    "        end_idx = i * batch_size\n",
    "        X_batches[i] = tensor(X_shuffled[:, start_idx:end_idx], requires_grad= false)\n",
    "        y_batches[i] = onehot(y_shuffled[start_idx:end_idx], num_classes = 10)\n",
    "    end\n",
    "\n",
    "    return (X_batches, y_batches)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 500)\n",
      "(10, 500)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "\n",
    "X_batches, y_batches = make_batches(X_train, y_train, batch_size)\n",
    "\n",
    "# Check size of first batch\n",
    "println(size(X_batches[1]))  \n",
    "println(size(y_batches[1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_train! (generic function with 1 method)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_train!(;model::NeuralNet, loss_fn::Function, X_batches::Vector{Tensor}, y_batches::Vector{Tensor}, lr::Float64=0.001, num_epochs::Integer = 10)\n",
    "    losses = zeros((num_epochs,))\n",
    "    for epoch_idx in 1:num_epochs\n",
    "        for batch_idx in 1:length(X_batches)\n",
    "            X = X_batches[batch_idx]\n",
    "            y = y_batches[batch_idx]\n",
    "            \n",
    "            pred = forward(model, X, postprocess = true)\n",
    "            loss = loss_fn(pred, y)\n",
    "            backward!(loss)\n",
    "            gd_step!(model, lr=lr)\n",
    "    \n",
    "            zerograd!(loss)\n",
    "            losses[epoch_idx] += loss.data[]\n",
    "        end\n",
    "        losses[epoch_idx] = losses[epoch_idx]/length(X_batches) # average loss for one epoch assuming equal batch sizes throughout\n",
    "        println(\"Epoch $(epoch_idx)\")\n",
    "        println(losses[epoch_idx])\n",
    "    end\n",
    "    return losses\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet((784, 128, 10), Dict{Integer, Tuple{Vararg{Tensor}}}(2 => (Tensor{Float64}((10, 128), Float64, [-0.5362769168183339 0.8814473188570807 … -0.30632781907938106 -1.6890148744989146; -1.9203930247082137 -1.0679086241480185 … -0.8397853257231505 -0.6349656704173873; … ; 0.518881809531327 -0.27522670890624085 … 1.611277465500551 -0.5627502112858949; 0.700643262126764 -0.08333367985594493 … -1.056570242644902 0.5810167786333293], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], true, true, (), \"\", nothing), Tensor{Float64}((10, 1), Float64, [0.3760772873669413; 0.585462349320713; … ; 0.5324475432883325; 0.407022516621718;;], [0.0; 0.0; … ; 0.0; 0.0;;], true, true, (), \"\", nothing)), 1 => (Tensor{Float64}((128, 784), Float64, [0.9737079685509828 0.6104133750631461 … -1.2497569265092767 -0.658421059715729; 0.243907085917515 0.8270763301074611 … 0.3219291400990193 -0.25463540367245824; … ; 1.1168341291454087 -0.5006505373450879 … 1.0302309625064647 1.070686835818576; -2.1062912326207024 -1.2440751863846287 … -0.1174931994669506 -1.2130979030243823], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], true, true, (), \"\", nothing), Tensor{Float64}((128, 1), Float64, [-0.4253887659885936; -0.4082403468445949; … ; -0.742795027900434; 0.6985988180067594;;], [0.0; 0.0; … ; 0.0; 0.0;;], true, true, (), \"\", nothing))), Main.relu, Main.softmax)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dims = (784, 128, 10)\n",
    "model = NeuralNet(layer_dims; activation_fn = relu, postprocess_fn = softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "8.500940535668246\n",
      "Epoch 2\n",
      "5.69430799347641\n",
      "Epoch 3\n",
      "1.9808809857976015\n",
      "Epoch 4\n",
      "0.9696586128743399\n",
      "Epoch 5\n",
      "0.7423564571075918\n",
      "Epoch 6\n",
      "0.6028110388575183\n",
      "Epoch 7\n",
      "0.5001859556713252\n",
      "Epoch 8\n",
      "0.42575422404108276\n",
      "Epoch 9\n",
      "0.3718036749606543\n",
      "Epoch 10\n",
      "0.3262101823018494\n",
      "Epoch 11\n",
      "0.29370984936541356\n",
      "Epoch 12\n",
      "0.2696770220170836\n",
      "Epoch 13\n",
      "0.24950815588921285\n",
      "Epoch 14\n",
      "0.2304618643153256\n",
      "Epoch 15\n",
      "0.2162772129389104\n",
      "Epoch 16\n",
      "0.20369196014781835\n",
      "Epoch 17\n",
      "0.192645116404912\n",
      "Epoch 18\n",
      "0.18272874251560955\n",
      "Epoch 19\n",
      "0.17233245786162102\n",
      "Epoch 20\n",
      "0.1645550247853558\n",
      "Epoch 21\n",
      "0.15714809933182827\n",
      "Epoch 22\n",
      "0.15056742125844097\n",
      "Epoch 23\n",
      "0.1453355612297749\n",
      "Epoch 24\n",
      "0.1408224477999845\n",
      "Epoch 25\n",
      "0.13634566815245286\n",
      "Epoch 26\n",
      "0.1327371464981884\n",
      "Epoch 27\n",
      "0.12943630558559147\n",
      "Epoch 28\n",
      "0.1266121804701754\n",
      "Epoch 29\n",
      "0.12362353485950325\n",
      "Epoch 30\n",
      "0.12117095060570428\n",
      "Epoch 31\n",
      "0.11920170669174245\n",
      "Epoch 32\n",
      "0.11717426301262936\n",
      "Epoch 33\n",
      "0.1153783810431348\n",
      "Epoch 34\n",
      "0.11385966072735872\n",
      "Epoch 35\n",
      "0.11239611568065347\n",
      "Epoch 36\n",
      "0.11137593868666441\n",
      "Epoch 37\n",
      "0.10984158886414819\n",
      "Epoch 38\n",
      "0.108615142808472\n",
      "Epoch 39\n",
      "0.1074863621032087\n",
      "Epoch 40\n",
      "0.10663029705654775\n",
      "Epoch 41\n",
      "0.10592469853856669\n",
      "Epoch 42\n",
      "0.10518953015787762\n",
      "Epoch 43\n",
      "0.10423637920749627\n",
      "Epoch 44\n",
      "0.1032010931946808\n",
      "Epoch 45\n",
      "0.10207652113089129\n",
      "Epoch 46\n",
      "0.10080835619161478\n",
      "Epoch 47\n",
      "0.09969777073435118\n",
      "Epoch 48\n",
      "0.09868886286053971\n",
      "Epoch 49\n",
      "0.09787244548794134\n",
      "Epoch 50\n",
      "0.09675047091086214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50-element Vector{Float64}:\n",
       " 8.500940535668246\n",
       " 5.69430799347641\n",
       " 1.9808809857976015\n",
       " 0.9696586128743399\n",
       " 0.7423564571075918\n",
       " 0.6028110388575183\n",
       " 0.5001859556713252\n",
       " 0.42575422404108276\n",
       " 0.3718036749606543\n",
       " 0.3262101823018494\n",
       " 0.29370984936541356\n",
       " 0.2696770220170836\n",
       " 0.24950815588921285\n",
       " ⋮\n",
       " 0.1074863621032087\n",
       " 0.10663029705654775\n",
       " 0.10592469853856669\n",
       " 0.10518953015787762\n",
       " 0.10423637920749627\n",
       " 0.1032010931946808\n",
       " 0.10207652113089129\n",
       " 0.10080835619161478\n",
       " 0.09969777073435118\n",
       " 0.09868886286053971\n",
       " 0.09787244548794134\n",
       " 0.09675047091086214"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = batch_train!(model = model, loss_fn = categorical_cross_entropy, X_batches= X_batches, y_batches = y_batches, num_epochs = 50, lr = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy_MNIST (generic function with 2 methods)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function accuracy_MNIST(model, X_test::Matrix{Float64}, y_test::Vector{Int64})\n",
    "    X_test = tensor(X_test, requires_grad = false)\n",
    "    preds = forward(model, X_test, postprocess = true) \n",
    "    preds2 = argmax(preds.data; dims =1)\n",
    "    first_elements = [preds2[i].I[1] for i in eachindex(preds2)]\n",
    "    preds3 = vec(first_elements)\n",
    "    return sum(preds3.-1 .== y_test)/length(y_test)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9577"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_MNIST(model, X_test,  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x \\xrightarrow{f} y $$\n",
    "$$f(x) =y$$\n",
    "$$\\frac{dL}{dx} = \\frac{dL}{dy} \\cdot \\frac{dy}{dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z = f(x,y) =\\frac{x}{y}$$\n",
    "$$\\frac{dL}{dx} = \\frac{dL}{dz} \\cdot \\frac{dz}{dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
